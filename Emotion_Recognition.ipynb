{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Libraries....\n",
      "\n",
      "Libraries Imported Successfully...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keshav/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "#Importing Libraries\n",
    "print('Importing Libraries....')\n",
    "print('')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import color\n",
    "from skimage.transform import resize\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Libraries Imported Successfully...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the  CSV file.....\n",
      "File successfully read!\n"
     ]
    }
   ],
   "source": [
    "#reading Dataset\n",
    "print('Reading the  CSV file.....')\n",
    "dataset=pd.read_csv('./fer2013.csv')\n",
    "# print(dataset.head())\n",
    "print('File successfully read!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the X-Values and Y-Values from Dataset.\n",
      "Please Wait....\n",
      "\n",
      "Success Achieved ....\n"
     ]
    }
   ],
   "source": [
    "#splitting the values of dataset into X and Y values\n",
    "Y_data=dataset.values[:,0].reshape(-1,1)\n",
    "X_data=dataset.values[:,1].reshape(-1,1)\n",
    "X_datlist=[]\n",
    "\n",
    "print('Getting the X-Values and Y-Values from Dataset.')\n",
    "print('Please Wait....')\n",
    "for x in X_data:\n",
    "    l1=list(x)\n",
    "    m1=list(map(float,l1[0].split()))\n",
    "    X_datlist.append(np.asarray(m1))\n",
    "X_datlist=np.asarray(X_datlist)\n",
    "\n",
    "Y_data_mat=[]\n",
    "for i in range(len(Y_data)):\n",
    "    x1=Y_data[i][0]\n",
    "\n",
    "    Y_data_mat.append(x1)\n",
    "\n",
    "Y_data=np.asarray(Y_data_mat)\n",
    "\n",
    "print('')\n",
    "print('Success Achieved ....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Data into Training and Testing...\n",
      "\n",
      "Converted Successfully.\n"
     ]
    }
   ],
   "source": [
    "#Getting the training and testing data ready\n",
    "print('Converting Data into Training and Testing...')\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X_datlist,Y_data,test_size=0.1)\n",
    "print('')\n",
    "print('Converted Successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing some of the Feature Scaling\n",
    "print('Doing some of the feature Scaling...Wait')\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print('Scaling Done Successfully..')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the model ready...\n",
      "Fitting the necessary data values...\n",
      "Model is Ready for Use...\n"
     ]
    }
   ],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "print('Getting the model ready...')\n",
    "classifier = RandomForestClassifier(n_estimators = 1000, criterion = 'gini', random_state = 42,class_weight=\"balanced\")\n",
    "print('Fitting the necessary data values...')\n",
    "classifier.fit(X_train,Y_train)\n",
    "\n",
    "print('Model is Ready for Use...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the accuracy over Testing Data\n",
      "Accuracy of the Model is  48.23070493173586 %\n"
     ]
    }
   ],
   "source": [
    "print('Checking the accuracy over Testing Data')\n",
    "\n",
    "Y_pred=classifier.predict(X_test)\n",
    "\n",
    "print('Accuracy of the Model is ',(accuracy_score(Y_pred,Y_test)*100),'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the Image...\n",
      "\n",
      "Done..\n",
      "\n",
      "Probability of being Anger     -->  17.15067210224769 %\n",
      "Probability of being Disgust   -->  2.4 %\n",
      "Probability of having Fear     -->  19.55829108774293 %\n",
      "Probability of being Happy     -->  21.9 %\n",
      "Probability of being Sad       -->  19.125208287656214 %\n",
      "Probability of being Surprised -->  8.165828522353166 %\n",
      "Probability of being Neutral   -->  11.700000000000001 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keshav/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "print('Reading the Image...\\n')\n",
    "img = io.imread('./image.jpeg', as_gray=True)\n",
    "image_resized = resize(img, (48, 48), anti_aliasing=True)\n",
    "X_get=[]\n",
    "for i in range(48):\n",
    "    for j in range(48):\n",
    "        X_get.append((int(round(image_resized[i][j]*210))))\n",
    "X_get=np.asarray(X_get).reshape(-1,1)\n",
    "X_get=np.transpose(X_get)\n",
    "predictions = classifier.predict_proba(X_get)\n",
    "print('Done..\\n')\n",
    "print(\"Probability of being Anger     --> \",predictions[0][0]*100,\"%\")\n",
    "print(\"Probability of being Disgust   --> \",predictions[0][1]*100,\"%\")\n",
    "print(\"Probability of having Fear     --> \",predictions[0][2]*100,\"%\")\n",
    "print(\"Probability of being Happy     --> \",predictions[0][3]*100,\"%\")\n",
    "print(\"Probability of being Sad       --> \",predictions[0][4]*100,\"%\")\n",
    "print(\"Probability of being Surprised --> \",predictions[0][5]*100,\"%\")\n",
    "print(\"Probability of being Neutral   --> \",predictions[0][6]*100,\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
